# -*- coding: utf-8 -*-
"""TABLE_III_CIFARVGG.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1GIAWX9OM7uHeiFUpJmePULiF1RWT5PbP

# CW3: VGG Model
"""

import tensorflow as tf

from tensorflow.keras import datasets, layers, models, optimizers, callbacks
# from keras.callbacks import EarlyStopping, ModelCheckpoint

import matplotlib.pyplot as plt

# !pip install --upgrade tensorflow

"""# Building ConvNet Configuration Types

https://arxiv.org/pdf/1409.1556.pdf (Page 3, Tables 1 & 2)
"""

cifar_shape = (32,32,3)
cifar_classes = 10

"""## Configuration: A (11 weight layers)"""

model_A = models.Sequential()

model_A.add(layers.Conv2D(64, (3, 3), padding='same', activation='relu', input_shape=cifar_shape))
model_A.add(layers.MaxPool2D((2, 2), strides=2, padding='same'))

model_A.add(layers.Conv2D(128, (3, 3), padding='same', activation='relu'))
model_A.add(layers.MaxPool2D((2, 2), strides=2, padding='same'))

model_A.add(layers.Conv2D(256, (3, 3), padding='same', activation='relu'))
model_A.add(layers.Conv2D(256, (3, 3), padding='same', activation='relu'))
model_A.add(layers.MaxPool2D((2, 2), strides=2, padding='same'))

model_A.add(layers.Conv2D(512, (3, 3), padding='same', activation='relu'))
model_A.add(layers.Conv2D(512, (3, 3), padding='same', activation='relu'))
model_A.add(layers.MaxPool2D((2, 2), strides=2, padding='same'))

model_A.add(layers.Conv2D(512, (3, 3), padding='same', activation='relu'))
model_A.add(layers.Conv2D(512, (3, 3), padding='same', activation='relu'))
model_A.add(layers.MaxPool2D((2, 2), strides=2, padding='same'))
model_A.add(layers.Dropout(0.5))

model_A.add(layers.Flatten())
model_A.add(layers.Dense(4096, activation='relu'))
model_A.add(layers.Dense(4096, activation='relu'))
model_A.add(layers.Dense(cifar_classes, activation='softmax'))

model_A.summary()
# Total params: 132,863,336 for ILSVRC
# Total params: 28,144,010 for CIFAR 
# Total params: 28,142,858 for MNIST

"""## Configuration: B (13 weight layers)"""

model_B = models.Sequential()

model_B.add(layers.Conv2D(64, (3, 3), padding='same', activation='relu', input_shape=cifar_shape))
model_B.add(layers.Conv2D(64, (3, 3), padding='same', activation='relu'))
model_B.add(layers.MaxPool2D((2, 2), strides=2, padding='same'))

model_B.add(layers.Conv2D(128, (3, 3), padding='same', activation='relu'))
model_B.add(layers.Conv2D(128, (3, 3), padding='same', activation='relu'))
model_B.add(layers.MaxPool2D((2, 2), strides=2, padding='same'))

model_B.add(layers.Conv2D(256, (3, 3), padding='same', activation='relu'))
model_B.add(layers.Conv2D(256, (3, 3), padding='same', activation='relu'))
model_B.add(layers.MaxPool2D((2, 2), strides=2, padding='same'))

model_B.add(layers.Conv2D(512, (3, 3), padding='same', activation='relu'))
model_B.add(layers.Conv2D(512, (3, 3), padding='same', activation='relu'))
model_B.add(layers.MaxPool2D((2, 2), strides=2, padding='same'))

model_B.add(layers.Conv2D(512, (3, 3), padding='same', activation='relu'))
model_B.add(layers.Conv2D(512, (3, 3), padding='same', activation='relu'))
model_B.add(layers.MaxPool2D((2, 2), strides=2, padding='same'))
model_B.add(layers.Dropout(0.5))

model_B.add(layers.Flatten())
model_B.add(layers.Dense(4096, activation='relu'))
model_B.add(layers.Dense(4096, activation='relu'))
model_B.add(layers.Dense(cifar_classes, activation='softmax'))

model_B.summary()
# Total params: 133,047,848 for ILSVRC
# Total params: 28,328,522 for CIFAR
# Total params: 28,327,370 for MNIST

"""## Configuration: C (16 weight layers)"""

model_C = models.Sequential()

model_C.add(layers.Conv2D(64, (3, 3), padding='same', activation='relu', input_shape=cifar_shape))
model_C.add(layers.Conv2D(64, (3, 3), padding='same', activation='relu'))
model_C.add(layers.MaxPool2D((2, 2), strides=2, padding='same'))

model_C.add(layers.Conv2D(128, (3, 3), padding='same', activation='relu'))
model_C.add(layers.Conv2D(128, (3, 3), padding='same', activation='relu'))
model_C.add(layers.MaxPool2D((2, 2), strides=2, padding='same'))

model_C.add(layers.Conv2D(256, (3, 3), padding='same', activation='relu'))
model_C.add(layers.Conv2D(256, (3, 3), padding='same', activation='relu'))
model_C.add(layers.Conv2D(256, (1, 1), padding='same', activation='relu'))
model_C.add(layers.MaxPool2D((2, 2), strides=2, padding='same'))

model_C.add(layers.Conv2D(512, (3, 3), padding='same', activation='relu'))
model_C.add(layers.Conv2D(512, (3, 3), padding='same', activation='relu'))
model_C.add(layers.Conv2D(512, (1, 1), padding='same', activation='relu'))
model_C.add(layers.MaxPool2D((2, 2), strides=2, padding='same'))

model_C.add(layers.Conv2D(512, (3, 3), padding='same', activation='relu'))
model_C.add(layers.Conv2D(512, (3, 3), padding='same', activation='relu'))
model_C.add(layers.Conv2D(512, (1, 1), padding='same', activation='relu'))
model_C.add(layers.MaxPool2D((2, 2), strides=2, padding='same'))
model_C.add(layers.Dropout(0.5))

model_C.add(layers.Flatten())
model_C.add(layers.Dense(4096, activation='relu'))
model_C.add(layers.Dense(4096, activation='relu'))
model_C.add(layers.Dense(cifar_classes, activation='softmax'))

model_C.summary()
# Total params: 133,638,952 for ILSVRC
# Total params: 28,919,626 for CIFAR
# Total params: 28,918,474 for MNIST

"""## Configuration: D (16 weight layers)"""

model_D = models.Sequential()

model_D.add(layers.Conv2D(64, (3, 3), padding='same', activation='relu', input_shape=cifar_shape))
model_D.add(layers.Conv2D(64, (3, 3), padding='same', activation='relu'))
model_D.add(layers.MaxPool2D((2, 2), strides=2, padding='same'))

model_D.add(layers.Conv2D(128, (3, 3), padding='same', activation='relu'))
model_D.add(layers.Conv2D(128, (3, 3), padding='same', activation='relu'))
model_D.add(layers.MaxPool2D((2, 2), strides=2, padding='same'))

model_D.add(layers.Conv2D(256, (3, 3), padding='same', activation='relu'))
model_D.add(layers.Conv2D(256, (3, 3), padding='same', activation='relu'))
model_D.add(layers.Conv2D(256, (3, 3), padding='same', activation='relu'))
model_D.add(layers.MaxPool2D((2, 2), strides=2, padding='same'))

model_D.add(layers.Conv2D(512, (3, 3), padding='same', activation='relu'))
model_D.add(layers.Conv2D(512, (3, 3), padding='same', activation='relu'))
model_D.add(layers.Conv2D(512, (3, 3), padding='same', activation='relu'))
model_D.add(layers.MaxPool2D((2, 2), strides=2, padding='same'))

model_D.add(layers.Conv2D(512, (3, 3), padding='same', activation='relu'))
model_D.add(layers.Conv2D(512, (3, 3), padding='same', activation='relu'))
model_D.add(layers.Conv2D(512, (3, 3), padding='same', activation='relu'))
model_D.add(layers.MaxPool2D((2, 2), strides=2, padding='same'))
model_D.add(layers.Dropout(0.5))

model_D.add(layers.Flatten())
model_D.add(layers.Dense(4096, activation='relu'))
model_D.add(layers.Dense(4096, activation='relu'))
model_D.add(layers.Dense(cifar_classes, activation='softmax'))

model_D.summary()
# Total params: 138,357,544 for ILSVRC
# Total params: 33,638,218 for CIFAR
# Total params: 33,637,066 for MNIST

"""## Configuration: E (19 weight layers, approx 144 million parameters)"""

model_E = models.Sequential()

model_E.add(layers.Conv2D(64, (3, 3), padding='same', activation='relu', input_shape=cifar_shape))
model_E.add(layers.Conv2D(64, (3, 3), padding='same', activation='relu'))
model_E.add(layers.MaxPool2D((2, 2), strides=2, padding='same'))

model_E.add(layers.Conv2D(128, (3, 3), padding='same', activation='relu'))
model_E.add(layers.Conv2D(128, (3, 3), padding='same', activation='relu'))
model_E.add(layers.MaxPool2D((2, 2), strides=2, padding='same'))

model_E.add(layers.Conv2D(256, (3, 3), padding='same', activation='relu'))
model_E.add(layers.Conv2D(256, (3, 3), padding='same', activation='relu'))
model_E.add(layers.Conv2D(256, (3, 3), padding='same', activation='relu'))
model_E.add(layers.Conv2D(256, (3, 3), padding='same', activation='relu'))
model_E.add(layers.MaxPool2D((2, 2), strides=2, padding='same'))

model_E.add(layers.Conv2D(512, (3, 3), padding='same', activation='relu'))
model_E.add(layers.Conv2D(512, (3, 3), padding='same', activation='relu'))
model_E.add(layers.Conv2D(512, (3, 3), padding='same', activation='relu'))
model_E.add(layers.Conv2D(512, (3, 3), padding='same', activation='relu'))
model_E.add(layers.MaxPool2D((2, 2), strides=2, padding='same'))

model_E.add(layers.Conv2D(512, (3, 3), padding='same', activation='relu'))
model_E.add(layers.Conv2D(512, (3, 3), padding='same', activation='relu'))
model_E.add(layers.Conv2D(512, (3, 3), padding='same', activation='relu'))
model_E.add(layers.Conv2D(512, (3, 3), padding='same', activation='relu'))
model_E.add(layers.MaxPool2D((2, 2), strides=2, padding='same'))
model_E.add(layers.Dropout(0.5))

model_E.add(layers.Flatten())
model_E.add(layers.Dense(4096, activation='relu'))
model_E.add(layers.Dense(4096, activation='relu'))
model_E.add(layers.Dense(cifar_classes, activation='softmax'))

model_E.summary()
# Total params: 143,667,240 for ILSVRC
# Total params: 38,947,914 for CIFAR
# Total params: 38,946,762 for MNIST

"""# Implementation of Models on Datasets"""

import tensorflow as tf
from tensorflow.keras import datasets
import matplotlib.pyplot as plt

"""## CIFAR10

The CIFAR10 dataset contains 60,000 color images in 10 classes, with 6,000 images in each class. The dataset is divided into 50,000 training images and 10,000 testing images. The classes are mutually exclusive and there is no overlap between them.
"""

(train_images_cifar, train_labels_cifar), (test_images_cifar, test_labels_cifar) = datasets.cifar10.load_data()

# Normalize pixel values to be between 0 and 1
train_images_cifar, test_images_cifar = train_images_cifar / 255.0, test_images_cifar / 255.0


print('train_images_cifar:', train_images_cifar.shape)
print('train_labels_cifar:', train_labels_cifar.shape)
print('test_images_cifar:', test_images_cifar.shape)
print('test_labels_cifar:', test_labels_cifar.shape)

"""To verify that the dataset looks correct, let's plot the first 25 images from the training set and display the class name below each image."""

class_names = ['airplane', 'automobile', 'bird', 'cat', 'deer',
               'dog', 'frog', 'horse', 'ship', 'truck']

plt.figure(figsize=(20,20))
for i in range(25):
    plt.subplot(5,5,i+1)
    plt.xticks([])
    plt.yticks([])
    plt.grid(False)
    plt.imshow(train_images_cifar[i], cmap=plt.cm.binary)
    # The CIFAR labels happen to be arrays, 
    # which is why you need the extra index
    plt.xlabel(class_names[train_labels_cifar[i][0]])
plt.show()

sgd = optimizers.SGD(learning_rate=0.01, decay=1e-6, momentum=0.9, nesterov=True)

model_A.compile(optimizer=sgd,
              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),
              metrics=['accuracy'])


history = model_A.fit(train_images_cifar, 
                      train_labels_cifar, 
                      batch_size=256,
                      epochs=100,
                      validation_data=(test_images_cifar, test_labels_cifar))

plt.plot(history.history["accuracy"])
plt.plot(history.history['val_accuracy'])
plt.plot(history.history['loss'])
plt.plot(history.history['val_loss'])
plt.title("model accuracy")
plt.ylabel("Accuracy")
plt.xlabel("Epoch")
plt.legend(["Accuracy","Validation Accuracy","loss","Validation Loss"])
plt.show()

sgd = optimizers.SGD(learning_rate=0.01, decay=1e-6, momentum=0.9, nesterov=True)

model_B.compile(optimizer=sgd,
              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),
              metrics=['accuracy'])


history = model_B.fit(train_images_cifar, 
                      train_labels_cifar, 
                      batch_size=256,
                      epochs=200,
                      validation_data=(test_images_cifar, test_labels_cifar))

plt.plot(history.history["accuracy"])
plt.plot(history.history['val_accuracy'])
plt.plot(history.history['loss'])
plt.plot(history.history['val_loss'])
plt.title("model accuracy")
plt.ylabel("Accuracy")
plt.xlabel("Epoch")
plt.legend(["Accuracy","Validation Accuracy","loss","Validation Loss"])
plt.show()

sgd = optimizers.SGD(learning_rate=0.01, decay=1e-6, momentum=0.9, nesterov=True)

model_C.compile(optimizer=sgd,
              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),
              metrics=['accuracy'])


history = model_C.fit(train_images_cifar, 
                      train_labels_cifar, 
                      batch_size=256,
                      epochs=100,
                      validation_data=(test_images_cifar, test_labels_cifar))

plt.plot(history.history["accuracy"])
plt.plot(history.history['val_accuracy'])
plt.plot(history.history['loss'])
plt.plot(history.history['val_loss'])
plt.title("model accuracy")
plt.ylabel("Accuracy")
plt.xlabel("Epoch")
plt.legend(["Accuracy","Validation Accuracy","loss","Validation Loss"])
plt.show()

sgd = optimizers.SGD(learning_rate=0.01, decay=1e-6, momentum=0.9, nesterov=True)

model_D.compile(optimizer=sgd,
              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),
              metrics=['accuracy'])


history = model_D.fit(train_images_cifar, 
                      train_labels_cifar, 
                      batch_size=256,
                      epochs=100,
                      validation_data=(test_images_cifar, test_labels_cifar))

plt.plot(history.history["accuracy"])
plt.plot(history.history['val_accuracy'])
plt.plot(history.history['loss'])
plt.plot(history.history['val_loss'])
plt.title("model accuracy")
plt.ylabel("Accuracy")
plt.xlabel("Epoch")
plt.legend(["Accuracy","Validation Accuracy","loss","Validation Loss"])
plt.show()

sgd = optimizers.SGD(learning_rate=0.01, decay=1e-6, momentum=0.9, nesterov=True)

model_E.compile(optimizer=sgd,
              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),
              metrics=['accuracy'])


history = model_E.fit(train_images_cifar, 
                      train_labels_cifar, 
                      batch_size=256,
                      epochs=100,
                      validation_data=(test_images_cifar, test_labels_cifar))

plt.plot(history.history["accuracy"])
plt.plot(history.history['val_accuracy'])
plt.plot(history.history['loss'])
plt.plot(history.history['val_loss'])
plt.title("model accuracy")
plt.ylabel("Accuracy")
plt.xlabel("Epoch")
plt.legend(["Accuracy","Validation Accuracy","loss","Validation Loss"])
plt.show()